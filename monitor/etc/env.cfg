#!/bin/bash

# Notifications, set comma (,) separated email IDs for individual recepients.
#SENDTO="att-gvs-support@guavus.com"
SENDTO="robert.phillips@guavus.com,samuel.joseph@guavus.com,shailendra.kumar@guavus.com,hannes.vanrooyen@guavus.com"
SENDCC="supreet.singh@guavus.com"
# Alerts - on/off
ALERTS_SWITCH="on"

# Environment
BASEPATH="/data/scripts/monitor"
VAR="${BASEPATH}/var"
ETC="${BASEPATH}/etc"
BIN="${BASEPATH}/bin"
KPIS="${VAR}/kpis"
ALERTS="${VAR}/alerts"
LOGS="${VAR}/logs"
KPIBINARY="${BIN}/KPI"
TRIGGERBINARY="${BIN}/TRIGGERS"
ACTIONBINARY="${BIN}/ACTIONS"

# Binaries
SSH='/usr/bin/ssh -q -o ConnectTimeout=5 -o UserKnownHostsFile=/dev/null -l root '
SADF=`which sadf`
AWK=`which awk`
DATE=`which date`
CLI='/opt/tms/bin/cli -t "en" "conf t" '
PMX='/opt/tps/bin/pmx.py'
HADOOP='/opt/hadoop/bin/hadoop'
RSYNC='/usr/bin/rsync'
RSYNCOPT=' -azr '
NOTIFY="/usr/sbin/sendmail -i -t "
am_i_master() {  
# Check if cluster enabled or not #
enabled=''; enabled=`/opt/tms/bin/cli -t 'en' 'conf t' 'show cluster configured' | grep 'Cluster enabled' | awk -F ':' '{print $NF}' | sed 's/ //g'`
if [[ "${enabled}" == 'yes' ]]; then 
  standby=`/opt/tms/bin/cli -t "en" "conf t" "show cluster standby" | /bin/grep "Node internal address" | awk -F ":" '{print $2}' | awk -F "," '{print $1}' | sed 's/ //g'`; 
  vip=`/opt/tms/bin/cli -t 'en' 'conf t' 'show cluster configured' | /bin/grep "master virtual IP address" | awk '{print $NF}' | awk -F/ '{print $1}'`; 
  out='';out=`/sbin/ifconfig -a | /bin/grep ${vip}`; 
  if [[ $? -ne '0' ]]; then 
    echo "0";
  else
    echo "1"; 
  fi; 
else
  namenode=`/opt/tps/bin/pmx.py show hadoop | grep master | awk '{print $NF}' | sed 's/ //g'`
  out='';out=`/sbin/ifconfig -a | /bin/grep ${namenode}`;
  if [[ $? -ne '0' ]]; then
    echo "0";
  else
    echo "1";
  fi;
fi;
}

# Site Structure
IP="${ETC}/IP"
SITE="${BIN}/prepare-site.sh"
IB="${ETC}/IB"
THRESHOLDS="${ETC}/kpiThresholds.cfg"
THRESHOLDS_ACTION="${ETC}/actionThresholds.cfg"
DESCRIPTOR="${ETC}/kpiDescriptors.cfg"

# Application Specific
#COLBKPDIR=`${CLI} "show run full" | grep collector | grep backup-directory | awk '{print $NF}'`
OUTCOMPRESSEDFILES_HDFS="/data/output/DataFactory"
# Latency here means delay in hours, stands for the last 'nth' hour for calculating the application KPI values. Must not be greater than 5.
LATENCY=2
TIMEZ=UTC
DCNAME="gurgaon"

# Cleanup or KPI/ALERT/LOG retention (days).
ALERTRETENTION=3
KPIRETENTION=3
LOGRETENTION=3

# Following are the KPI list with switch options.
# Select from the following to change the frequency of corresponding KPI collection.
# ['memoryUtil','diskUtil','cpuUtil','nodeStatus','systemUptime','hadoopFSUtil','hadoopNodesAvailability','compressionRatioTotal','collectorStats']
# Note: Application specific KPIs collect hourly stats, therefore an hourly collection is suggested.
#       Reducing the frequency of these KPIs will result in redundant data. And, increasing the 
#       frequency of these KPIs to daily will result in a miss of 23 hours of KPI collection.
# Provide comma (,) separated list of KPI names. As shown in few samples.
kpi_oneMinute=''
kpi_fiveMinute='memoryUtil, cpuUtil'
kpi_tenMinute='systemUptime, hadoopFSUtil, hadoopNodesAvailability'
kpi_fifteenMinute='diskUtil'
kpi_thirtyMinute='nodeStatus'
#kpi_hourly='compressionRatioTotal, collectorStats, fileRetryCount'
kpi_hourly='compressionRatioTotal, collectorStats'
kpi_daily='collectorStatsDaily'

# Service Monitors
triggers_oneMinute=''
triggers_fiveMinute=''
triggers_tenMinute='collectorService'
triggers_fifteenMinute=''
triggers_thirtyMinute=''
triggers_hourly=''
triggers_daily=''

# Service Actions
actions_oneMinute=''
actions_fiveMinute='cleanEdrAsnBackup, stopCollectorCleanup, autoMountUnmountStreams'
actions_tenMinute=''
actions_fifteenMinute=''
actions_thirtyMinute=''
actions_hourly=''
actions_daily=''

# Site Report Size in hours.
# Specify the last 'n' hours for which the site report is expected. Please note that this parameter is used 
# to determine the size of the daily report which runs once a day.
REPORTSIZE=24

